{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSRS Parameter Divergence Exploration\n",
    "\n",
    "This notebook explores the divergence between 'Nature' (the ground truth stability) and the FSRS model predictions under various scenarios. \n",
    "\n",
    "## Setup\n",
    "We import the core simulation engine and optimized metric calculation logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm.auto import tqdm\n",
    "import concurrent.futures\n",
    "import multiprocessing\n",
    "\n",
    "# Add src to path for imports\n",
    "sys.path.append(os.path.abspath('src'))\n",
    "\n",
    "from simulate_fsrs import run_simulation, DEFAULT_PARAMETERS, load_anki_history, Card, Scheduler, infer_review_weights\n",
    "from plot_fsrs_divergence import calculate_metrics, calculate_population_retrievability, init_worker\n",
    "\n",
    "# Shared configuration\n",
    "REPEATS = 5\n",
    "CONCURRENCY = max(1, multiprocessing.cpu_count() // 2)\n",
    "SEED_HISTORY = 'collection.anki2' if os.path.exists('collection.anki2') else None\n",
    "DECK_CONFIG = 'Puzzles'\n",
    "T_EVAL = np.linspace(0, 100, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "Functions to run batches of simulations and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_scenario(tasks):\n",
    "    results = defaultdict(list)\n",
    "    \n",
    "    # Pre-load seeded payload for workers\n",
    "    seeded_payload = None\n",
    "    if SEED_HISTORY:\n",
    "        logs, last_rev = load_anki_history(SEED_HISTORY, deck_config_name=DECK_CONFIG)\n",
    "        if logs:\n",
    "            weights = infer_review_weights(logs)\n",
    "            nat_sch = Scheduler(parameters=DEFAULT_PARAMETERS)\n",
    "            alg_sch = Scheduler(parameters=DEFAULT_PARAMETERS)\n",
    "            true_cards = {}\n",
    "            sys_cards = {}\n",
    "            for cid, card_logs in logs.items():\n",
    "                true_cards[cid] = nat_sch.reschedule_card(Card(card_id=cid), card_logs)\n",
    "                sys_cards[cid] = alg_sch.reschedule_card(Card(card_id=cid), card_logs)\n",
    "            \n",
    "            seeded_payload = {\n",
    "                'logs': logs,\n",
    "                'last_rev': last_rev,\n",
    "                'true_cards': true_cards,\n",
    "                'sys_cards': sys_cards,\n",
    "                'weights': weights\n",
    "            }\n",
    "\n",
    "    with concurrent.futures.ProcessPoolExecutor(\n",
    "        max_workers=CONCURRENCY,\n",
    "        initializer=init_worker,\n",
    "        initargs=(seeded_payload,)\n",
    "    ) as executor:\n",
    "        future_to_task = {}\n",
    "        for task_label, task_params in tasks.items():\n",
    "            for i in range(REPEATS):\n",
    "                t = dict(task_params)\n",
    "                t['seed'] = 42 + i\n",
    "                t['verbose'] = False\n",
    "                t['seeded_data'] = None\n",
    "                future = executor.submit(run_simulation, **t)\n",
    "                future_to_task[future] = task_label\n",
    "\n",
    "        for future in tqdm(concurrent.futures.as_completed(future_to_task), total=len(future_to_task)):\n",
    "            label = future_to_task[future]\n",
    "            try:\n",
    "                fitted, gt, metrics = future.result()\n",
    "                if fitted:\n",
    "                    stabilities = metrics['stabilities']\n",
    "                    rmse, kl = calculate_metrics(gt, fitted, stabilities)\n",
    "                    \n",
    "                    s_nat = np.array([s[0] for s in stabilities])\n",
    "                    s_alg = np.array([s[1] for s in stabilities])\n",
    "                    r_nat = calculate_population_retrievability(T_EVAL, s_nat, gt)\n",
    "                    r_fit = calculate_population_retrievability(T_EVAL, s_alg, fitted)\n",
    "                    \n",
    "                    results[label].append({\n",
    "                        'rmse': rmse,\n",
    "                        'kl': kl,\n",
    "                        'r_nat': r_nat,\n",
    "                        'r_fit': r_fit\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f'Task {label} failed: {e}')\n",
    "    return results\n",
    "\n",
    "def plot_results(scenario_results, title):\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for label, repeats in scenario_results.items():\n",
    "        avg_fit = np.mean([r['r_fit'] for r in repeats], axis=0)\n",
    "        avg_nat = np.mean([r['r_nat'] for r in repeats], axis=0)\n",
    "        avg_rmse = np.mean([r['rmse'] for r in repeats])\n",
    "        avg_kl = np.mean([r['kl'] for r in repeats])\n",
    "        \n",
    "        line, = plt.plot(T_EVAL, avg_fit, label=f'{label} (RMSE: {avg_rmse:.4f}, KL: {avg_kl:.4f})')\n",
    "        plt.plot(T_EVAL, avg_nat, linestyle='--', color=line.get_color(), alpha=0.5)\n",
    "        \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Days since end of simulation')\n",
    "    plt.ylabel('Aggregate Expected Retention')\n",
    "    plt.legend(fontsize='small', ncol=1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 1: Duration Exploration\n",
    "Default parameters, 0.9 retention for different time periods (30, 90, 180, 365 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_1 = {\n",
    "    '30 Days': {'n_days': 30, 'retention': '0.9'},\n",
    "    '90 Days': {'n_days': 90, 'retention': '0.9'},\n",
    "    '180 Days': {'n_days': 180, 'retention': '0.9'},\n",
    "    '365 Days': {'n_days': 365, 'retention': '0.9'}\n",
    "}\n",
    "res_1 = run_scenario(tasks_1)\n",
    "plot_results(res_1, 'Scenario 1: Impact of Simulation Duration (0.9 Retention)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 2: Retention Contrast\n",
    "Default parameters, 0.9 vs 0.7 retention for the same time period (180 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_2 = {\n",
    "    'Ret=0.9': {'n_days': 180, 'retention': '0.9'},\n",
    "    'Ret=0.7': {'n_days': 180, 'retention': '0.7'}\n",
    "}\n",
    "res_2 = run_scenario(tasks_2)\n",
    "plot_results(res_2, 'Scenario 2: Impact of Target Retention (180 Days)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 3: Static 0.9 vs Variable Schedule\n",
    "Default params, static 0.9 vs a 5:1 weighted schedule favoring 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_3 = {\n",
    "    'Static 0.9': {'n_days': 180, 'retention': '0.9'},\n",
    "    'Sched 0.9:5,0.7:1': {'n_days': 180, 'retention': '5:0.9,1:0.7'}\n",
    "}\n",
    "res_3 = run_scenario(tasks_3)\n",
    "plot_results(res_3, 'Scenario 3: Static 0.9 vs 0.9:5,0.7:1 Schedule')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 4: Static 0.7 vs Variable Schedule\n",
    "Default params, static 0.7 vs a 5:1 weighted schedule favoring 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_4 = {\n",
    "    'Static 0.7': {'n_days': 180, 'retention': '0.7'},\n",
    "    'Sched 0.7:5,0.9:1': {'n_days': 180, 'retention': '5:0.7,1:0.9'}\n",
    "}\n",
    "res_4 = run_scenario(tasks_4)\n",
    "plot_results(res_4, 'Scenario 4: Static 0.7 vs 0.7:5,0.9:1 Schedule')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 5: High-Retention Burn-In\n",
    "Default params, 60 days of 0.9 burn-in followed by a shift to 0.7 vs staying at 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_5 = {\n",
    "    '0.9 BI -> 0.7 post': {'n_days': 180, 'burn_in_days': 60, 'retention': '60:0.9,120:0.7'}\n",
    "    '0.9 BI -> 0.7 post': {'n_days': 180, 'burn_in_days': 60, 'retention': '60:0.9,120:0.7'},\n",
    "}\n",
    "res_5 = run_scenario(tasks_5)\n",
    "plot_results(res_5, 'Scenario 5: Post-Burn-In Retention Shift (0.9 Initial)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scenario 6: Low-Retention Burn-In\n",
    "Default params, 60 days of 0.7 burn-in followed by a shift to 0.9 vs staying at 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_6 = {\n",
    "    '0.7 BI -> 0.7 post': {'n_days': 180, 'burn_in_days': 60, 'retention': '0.7'}\n",
    "    '0.7 BI -> 0.7 post': {'n_days': 180, 'burn_in_days': 60, 'retention': '0.7'},\n",
    "}\n",
    "res_6 = run_scenario(tasks_6)\n",
    "plot_results(res_6, 'Scenario 6: Post-Burn-In Retention Shift (0.7 Initial)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}